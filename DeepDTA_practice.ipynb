{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOMwjc7zcX2Av6U2WypBd33",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PhazeRoOman/DeepDTA/blob/Menna's-branch/DeepDTA_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DeepDTA: deep drugâ€“target binding affinity prediction**\n",
        "\n",
        "Source: https://github.com/hkmztrk/DeepDTA"
      ],
      "metadata": {
        "id": "ygOipmGh84l2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlBxLcBd-HtC",
        "outputId": "965a0ce5-b0ea-4a28-9233-fe2b553cc67a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydot\n",
        "!pip install pydot_ng\n",
        "!pip install\n",
        "!pip install plot_model"
      ],
      "metadata": {
        "id": "q8tDSR5_AxNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports:"
      ],
      "metadata": {
        "id": "qbUcbI8m9JSQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "0wxo0iCL8L6h"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import decimal\n",
        "import argparse\n",
        "import subprocess\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random as rn\n",
        "import sys, pickle\n",
        "import math, json, time\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.mlab as mlab\n",
        "from random import shuffle\n",
        "from collections import OrderedDict\n",
        "from copy import deepcopy\n",
        "from sklearn import preprocessing\n",
        "from __future__ import print_function\n",
        "from itertools import product\n",
        "from collections import namedtuple\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.models import Model\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Conv1D, GlobalMaxPooling1D, MaxPooling1D\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import Conv2D, GRU\n",
        "from keras.layers import Input, Embedding, LSTM, TimeDistributed, Masking, RepeatVector, Flatten\n",
        "from keras.layers import Bidirectional\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras import optimizers, layers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#update the package lists\n",
        "!sudo apt-get update -y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTuD3pxX-ucC",
        "outputId": "f937c60a-2096-4288-964d-0ba88a516aee"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease [18.1 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n",
            "Get:8 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [979 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,236 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [876 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [49.8 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,110 kB]\n",
            "Hit:14 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [840 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [862 kB]\n",
            "Hit:17 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:18 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main Sources [2,163 kB]\n",
            "Get:19 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main amd64 Packages [1,110 kB]\n",
            "Fetched 9,585 kB in 7s (1,377 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print tensorflow version\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrWAwV37-h25",
        "outputId": "870b368d-3d13-4132-85a8-b33b2d57de82"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['PYTHONHASHSEED'] = '0'\n",
        "np.random.seed(1)\n",
        "rn.seed(1)\n",
        "tf.random.set_seed(0)\n",
        "\n",
        "TABSY = \"\\t\"\n",
        "figdir = \"figures/\""
      ],
      "metadata": {
        "id": "iDuhnTv29-t6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/PhazeRoOman/DeepDTA.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8KwYm2V--1_",
        "outputId": "872ba44a-d7fa-4ce9-d198-294b442d363e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DeepDTA'...\n",
            "remote: Enumerating objects: 447, done.\u001b[K\n",
            "remote: Counting objects: 100% (49/49), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 447 (delta 38), reused 29 (delta 29), pack-reused 398\u001b[K\n",
            "Receiving objects: 100% (447/447), 11.00 MiB | 4.80 MiB/s, done.\n",
            "Resolving deltas: 100% (179/179), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/DeepDTA"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wi70ctWrNGAM",
        "outputId": "d80565b3-a028-400b-8a3a-4e2cdca9e048"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DeepDTA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLR-oYdghWJ3",
        "outputId": "cb552d7d-e83f-45c8-ed2d-302a53adc52c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data  deepdta-toy  docs  README.md  source\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Arguments functions\n",
        "def argparser():\n",
        "  parser = argparse.ArgumentParser()\n",
        "  # for model\n",
        "  parser.add_argument(\n",
        "      '--seq_window_lengths',\n",
        "      type=int,\n",
        "      nargs='+',\n",
        "      help='Space seperated list of motif filter lengths. (ex, --window_lengths 4 8 12)'\n",
        "  )\n",
        "  parser.add_argument(\n",
        "      '--smi_window_lengths',\n",
        "      type=int,\n",
        "      nargs='+',\n",
        "      help='Space seperated list of motif filter lengths. (ex, --window_lengths 4 8 12)'\n",
        "  )\n",
        "  parser.add_argument(\n",
        "      '--num_windows',\n",
        "      type=int,\n",
        "      nargs='+',\n",
        "      help='Space seperated list of the number of motif filters corresponding to length list. (ex, --num_windows 100 200 100)'\n",
        "  )\n",
        "  parser.add_argument(\n",
        "      '--num_hidden',\n",
        "      type=int,\n",
        "      default=0,\n",
        "      help='Number of neurons in hidden layer.'\n",
        "  )\n",
        "  parser.add_argument(\n",
        "      '--num_classes',\n",
        "      type=int,\n",
        "      default=0,\n",
        "      help='Number of classes (families).'\n",
        "  )\n",
        "  parser.add_argument(\n",
        "      '--max_seq_len',\n",
        "      type=int,\n",
        "      default=0,\n",
        "      help='Length of input sequences.'\n",
        "  )\n",
        "  parser.add_argument(\n",
        "      '--max_smi_len',\n",
        "      type=int,\n",
        "      default=0,\n",
        "      help='Length of input sequences.'\n",
        "  )\n",
        "  # for learning\n",
        "  parser.add_argument(\n",
        "      '--learning_rate',\n",
        "      type=float,\n",
        "      default=0.001,\n",
        "      help='Initial learning rate.'\n",
        "  )\n",
        "  parser.add_argument(\n",
        "      '--num_epoch',\n",
        "      type=int,\n",
        "      default=100,\n",
        "      help='Number of epochs to train.'\n",
        "  )\n",
        "  parser.add_argument(\n",
        "      '--batch_size',\n",
        "      type=int,\n",
        "      default=256,\n",
        "      help='Batch size. Must divide evenly into the dataset sizes.'\n",
        "  )\n",
        "  parser.add_argument(\n",
        "      '--dataset_path',\n",
        "      type=str,\n",
        "      default='/data/kiba/',\n",
        "      help='Directory for input data.'\n",
        "  )\n",
        "  parser.add_argument(\n",
        "      '--problem_type',\n",
        "      type=int,\n",
        "      default=1,\n",
        "      help='Type of the prediction problem (1-4)'\n",
        "  )\n",
        "  parser.add_argument(\n",
        "      '--binary_th',\n",
        "      type=float,\n",
        "      default=0.0,\n",
        "      help='Threshold to split data into binary classes'\n",
        "  )\n",
        "  parser.add_argument(\n",
        "      '--is_log',\n",
        "      type=int,\n",
        "      default=0,\n",
        "      help='use log transformation for Y'\n",
        "  )\n",
        "  parser.add_argument(\n",
        "      '--checkpoint_path',\n",
        "      type=str,\n",
        "      default='',\n",
        "      help='Path to write checkpoint file.'\n",
        "  )\n",
        "  parser.add_argument(\n",
        "      '--log_dir',\n",
        "      type=str,\n",
        "      default='/tmp',\n",
        "      help='Directory for log data.'\n",
        "  )\n",
        "\n",
        "  FLAGS, unparsed = parser.parse_known_args()\n",
        "\n",
        "  # check validity\n",
        "  #assert( len(FLAGS.window_lengths) == len(FLAGS.num_windows) )\n",
        "\n",
        "  return FLAGS\n",
        "\n",
        "def logging(msg, FLAGS):\n",
        "  fpath = os.path.join( FLAGS.log_dir, \"log.txt\" )\n",
        "  with open( fpath, \"a\" ) as fw:\n",
        "    fw.write(\"%s\\n\" % msg)\n",
        "  #print(msg)"
      ],
      "metadata": {
        "id": "C1XFOJtc_nUo"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#emetrics functions\n",
        "def get_aupr(Y, P):\n",
        "    if hasattr(Y, 'A'): Y = Y.A\n",
        "    if hasattr(P, 'A'): P = P.A\n",
        "    Y = np.where(Y>0, 1, 0)\n",
        "    Y = Y.ravel()\n",
        "    P = P.ravel()\n",
        "    f = open(\"temp.txt\", 'w')\n",
        "    for i in range(Y.shape[0]):\n",
        "        f.write(\"%f %d\\n\" %(P[i], Y[i]))\n",
        "    f.close()\n",
        "    f = open(\"foo.txt\", 'w')\n",
        "    subprocess.call([\"java\", \"-jar\", \"auc.jar\", \"temp.txt\", \"list\"], stdout=f)\n",
        "    f.close()\n",
        "    f = open(\"foo.txt\")\n",
        "    lines = f.readlines()\n",
        "    aucpr = float(lines[-2].split()[-1])\n",
        "    f.close()\n",
        "    return aucpr\n",
        "\n",
        "\n",
        "\n",
        "def get_cindex(Y, P):\n",
        "    summ = 0\n",
        "    pair = 0\n",
        "\n",
        "    for i in range(1, len(Y)):\n",
        "        for j in range(0, i):\n",
        "            if i != j:\n",
        "                if(Y[i] > Y[j]):\n",
        "                    pair +=1\n",
        "                    summ +=  1* (P[i] > P[j]) + 0.5 * (P[i] == P[j])\n",
        "\n",
        "\n",
        "    if pair != 0:\n",
        "        return summ/pair\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "\n",
        "def r_squared_error(y_obs,y_pred):\n",
        "    y_obs = np.array(y_obs)\n",
        "    y_pred = np.array(y_pred)\n",
        "    y_obs_mean = [np.mean(y_obs) for y in y_obs]\n",
        "    y_pred_mean = [np.mean(y_pred) for y in y_pred]\n",
        "\n",
        "    mult = sum((y_pred - y_pred_mean) * (y_obs - y_obs_mean))\n",
        "    mult = mult * mult\n",
        "\n",
        "    y_obs_sq = sum((y_obs - y_obs_mean)*(y_obs - y_obs_mean))\n",
        "    y_pred_sq = sum((y_pred - y_pred_mean) * (y_pred - y_pred_mean) )\n",
        "\n",
        "    return mult / float(y_obs_sq * y_pred_sq)\n",
        "\n",
        "\n",
        "def get_k(y_obs,y_pred):\n",
        "    y_obs = np.array(y_obs)\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "    return sum(y_obs*y_pred) / float(sum(y_pred*y_pred))\n",
        "\n",
        "\n",
        "def squared_error_zero(y_obs,y_pred):\n",
        "    k = get_k(y_obs,y_pred)\n",
        "\n",
        "    y_obs = np.array(y_obs)\n",
        "    y_pred = np.array(y_pred)\n",
        "    y_obs_mean = [np.mean(y_obs) for y in y_obs]\n",
        "    upp = sum((y_obs - (k*y_pred)) * (y_obs - (k* y_pred)))\n",
        "    down= sum((y_obs - y_obs_mean)*(y_obs - y_obs_mean))\n",
        "\n",
        "    return 1 - (upp / float(down))\n",
        "\n",
        "\n",
        "def get_rm2(ys_orig,ys_line):\n",
        "    r2 = r_squared_error(ys_orig, ys_line)\n",
        "    r02 = squared_error_zero(ys_orig, ys_line)\n",
        "\n",
        "    return r2 * (1 - np.sqrt(np.absolute((r2*r2)-(r02*r02))))"
      ],
      "metadata": {
        "id": "-gLco2iA_xLy"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_combined_onehot(FLAGS, NUM_FILTERS, FILTER_LENGTH1, FILTER_LENGTH2):\n",
        "    XDinput = Input(shape=(FLAGS.max_smi_len, FLAGS.charsmiset_size))\n",
        "    XTinput = Input(shape=(FLAGS.max_seq_len, FLAGS.charseqset_size))\n",
        "\n",
        "\n",
        "    encode_smiles= Conv1D(filters=NUM_FILTERS, kernel_size=FILTER_LENGTH1,  activation='relu', padding='valid',  strides=1)(XDinput)\n",
        "    encode_smiles = Conv1D(filters=NUM_FILTERS*2, kernel_size=FILTER_LENGTH1,  activation='relu', padding='valid',  strides=1)(encode_smiles)\n",
        "    encode_smiles = Conv1D(filters=NUM_FILTERS*3, kernel_size=FILTER_LENGTH1,  activation='relu', padding='valid',  strides=1)(encode_smiles)\n",
        "    encode_smiles = GlobalMaxPooling1D()(encode_smiles) #pool_size=pool_length[i]\n",
        "\n",
        "\n",
        "    encode_protein = Conv1D(filters=NUM_FILTERS, kernel_size=FILTER_LENGTH2,  activation='relu', padding='valid',  strides=1)(XTinput)\n",
        "    encode_protein = Conv1D(filters=NUM_FILTERS*2, kernel_size=FILTER_LENGTH2,  activation='relu', padding='valid',  strides=1)(encode_protein)\n",
        "    encode_protein = Conv1D(filters=NUM_FILTERS*3, kernel_size=FILTER_LENGTH2,  activation='relu', padding='valid',  strides=1)(encode_protein)\n",
        "    encode_protein = GlobalMaxPooling1D()(encode_protein)\n",
        "\n",
        "\n",
        "\n",
        "    encode_interaction = keras.layers.concatenate([encode_smiles, encode_protein])\n",
        "    #encode_interaction = keras.layers.concatenate([encode_smiles, encode_protein], axis=-1) #merge.Add()([encode_smiles, encode_protein])\n",
        "\n",
        "    # Fully connected\n",
        "    FC1 = Dense(1024, activation='relu')(encode_interaction)\n",
        "    FC2 = Dropout(0.1)(FC1)\n",
        "    FC2 = Dense(1024, activation='relu')(FC2)\n",
        "    FC2 = Dropout(0.1)(FC2)\n",
        "    FC2 = Dense(512, activation='relu')(FC2)\n",
        "\n",
        "\n",
        "    predictions = Dense(1, kernel_initializer='normal')(FC2)\n",
        "\n",
        "    interactionModel = Model(inputs=[XDinput, XTinput], outputs=[predictions])\n",
        "    interactionModel.compile(optimizer='adam', loss='mean_squared_error', metrics=[cindex_score]) #, metrics=['cindex_score']\n",
        "\n",
        "\n",
        "    print(interactionModel.summary())\n",
        "    plot_model(interactionModel, to_file='figures/build_combined_onehot.png')\n",
        "\n",
        "    return interactionModel"
      ],
      "metadata": {
        "id": "ru8v402BAu24"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_combined_categorical(FLAGS, NUM_FILTERS, FILTER_LENGTH1, FILTER_LENGTH2):\n",
        "\n",
        "    XDinput = Input(shape=(FLAGS.max_smi_len,), dtype='int32') ### Buralar flagdan gelmeliii\n",
        "    XTinput = Input(shape=(FLAGS.max_seq_len,), dtype='int32')\n",
        "\n",
        "    ### SMI_EMB_DINMS  FLAGS GELMELII\n",
        "    encode_smiles = Embedding(input_dim=FLAGS.charsmiset_size+1, output_dim=128, input_length=FLAGS.max_smi_len)(XDinput)\n",
        "    encode_smiles = Conv1D(filters=NUM_FILTERS, kernel_size=FILTER_LENGTH1,  activation='relu', padding='valid',  strides=1)(encode_smiles)\n",
        "    encode_smiles = Conv1D(filters=NUM_FILTERS*2, kernel_size=FILTER_LENGTH1,  activation='relu', padding='valid',  strides=1)(encode_smiles)\n",
        "    encode_smiles = Conv1D(filters=NUM_FILTERS*3, kernel_size=FILTER_LENGTH1,  activation='relu', padding='valid',  strides=1)(encode_smiles)\n",
        "    encode_smiles = GlobalMaxPooling1D()(encode_smiles)\n",
        "\n",
        "\n",
        "    encode_protein = Embedding(input_dim=FLAGS.charseqset_size+1, output_dim=128, input_length=FLAGS.max_seq_len)(XTinput)\n",
        "    encode_protein = Conv1D(filters=NUM_FILTERS, kernel_size=FILTER_LENGTH2,  activation='relu', padding='valid',  strides=1)(encode_protein)\n",
        "    encode_protein = Conv1D(filters=NUM_FILTERS*2, kernel_size=FILTER_LENGTH2,  activation='relu', padding='valid',  strides=1)(encode_protein)\n",
        "    encode_protein = Conv1D(filters=NUM_FILTERS*3, kernel_size=FILTER_LENGTH2,  activation='relu', padding='valid',  strides=1)(encode_protein)\n",
        "    encode_protein = GlobalMaxPooling1D()(encode_protein)\n",
        "\n",
        "\n",
        "    encode_interaction = keras.layers.concatenate([encode_smiles, encode_protein], axis=-1) #merge.Add()([encode_smiles, encode_protein])\n",
        "\n",
        "    # Fully connected\n",
        "    FC1 = Dense(1024, activation='relu')(encode_interaction)\n",
        "    FC2 = Dropout(0.1)(FC1)\n",
        "    FC2 = Dense(1024, activation='relu')(FC2)\n",
        "    FC2 = Dropout(0.1)(FC2)\n",
        "    FC2 = Dense(512, activation='relu')(FC2)\n",
        "\n",
        "\n",
        "    # And add a logistic regression on top\n",
        "    predictions = Dense(1, kernel_initializer='normal')(FC2) #OR no activation, rght now it's between 0-1, do I want this??? activation='sigmoid'\n",
        "\n",
        "    interactionModel = Model(inputs=[XDinput, XTinput], outputs=[predictions])\n",
        "\n",
        "    interactionModel.compile(optimizer='adam', loss='mean_squared_error', metrics=[cindex_score]) #, metrics=['cindex_score']\n",
        "    print(interactionModel.summary())\n",
        "    # plot_model(interactionModel, to_file='figures/build_combined_categorical.png')\n",
        "\n",
        "    return interactionModel"
      ],
      "metadata": {
        "id": "poSZDZn5BAcM"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_single_drug(FLAGS, NUM_FILTERS, FILTER_LENGTH1, FILTER_LENGTH2):\n",
        "\n",
        "    interactionModel = Sequential()\n",
        "    XTmodel = Sequential()\n",
        "    XTmodel.add(Activation('linear', input_shape=(FLAGS.target_count,)))\n",
        "\n",
        "\n",
        "    encode_smiles = Sequential()\n",
        "    encode_smiles.add(Embedding(input_dim=FLAGS.charsmiset_size+1, output_dim=128, input_length=FLAGS.max_smi_len))\n",
        "    encode_smiles.add(Conv1D(filters=NUM_FILTERS, kernel_size=FILTER_LENGTH1,  activation='relu', padding='valid',  strides=1)) #input_shape=(MAX_SMI_LEN, SMI_EMBEDDING_DIMS)\n",
        "    encode_smiles.add(Conv1D(filters=NUM_FILTERS*2, kernel_size=FILTER_LENGTH1,  activation='relu', padding='valid',  strides=1))\n",
        "    encode_smiles.add(Conv1D(filters=NUM_FILTERS*3, kernel_size=FILTER_LENGTH1,  activation='relu', padding='valid',  strides=1))\n",
        "    encode_smiles.add(GlobalMaxPooling1D())\n",
        "\n",
        "\n",
        "    # interactionModel.add(Merge([encode_smiles, XTmodel], mode='concat', concat_axis=1))\n",
        "    # #interactionModel.add(layers.merge.Concatenate([XDmodel, XTmodel]))\n",
        "    interactionModel.add(layers.Concatenate([encode_smiles, XTmodel]))\n",
        "\n",
        "    # Fully connected\n",
        "    interactionModel.add(Dense(1024, activation='relu')) #1024\n",
        "    interactionModel.add(Dropout(0.1))\n",
        "    interactionModel.add(Dense(1024, activation='relu')) #1024\n",
        "    interactionModel.add(Dropout(0.1))\n",
        "    interactionModel.add(Dense(512, activation='relu'))\n",
        "\n",
        "\n",
        "    interactionModel.add(Dense(1, kernel_initializer='normal'))\n",
        "    interactionModel.compile(optimizer='adam', loss='mean_squared_error', metrics=[cindex_score])\n",
        "\n",
        "    print(interactionModel.summary())\n",
        "    plot_model(interactionModel, to_file='figures/build_single_drug.png')\n",
        "\n",
        "    return interactionModel"
      ],
      "metadata": {
        "id": "IWtMtFFQBCpg"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_single_prot(FLAGS, NUM_FILTERS, FILTER_LENGTH1, FILTER_LENGTH2):\n",
        "\n",
        "    interactionModel = Sequential()\n",
        "    XDmodel = Sequential()\n",
        "    XDmodel.add(Activation('linear', input_shape=(FLAGS.drugcount,)))\n",
        "\n",
        "\n",
        "    XTmodel1 = Sequential()\n",
        "    XTmodel1.add(Embedding(input_dim=FLAGS.charseqset_size+1, output_dim=128,  input_length=FLAGS.max_seq_len))\n",
        "    XTmodel1.add(Conv1D(filters=NUM_FILTERS, kernel_size=FILTER_LENGTH2,  activation='relu', padding='valid',  strides=1)) #input_shape=(MAX_SEQ_LEN, SEQ_EMBEDDING_DIMS)\n",
        "    XTmodel1.add(Conv1D(filters=NUM_FILTERS*2, kernel_size=FILTER_LENGTH2,  activation='relu', padding='valid',  strides=1))\n",
        "    XTmodel1.add(Conv1D(filters=NUM_FILTERS*3, kernel_size=FILTER_LENGTH2,  activation='relu', padding='valid',  strides=1))\n",
        "    XTmodel1.add(GlobalMaxPooling1D())\n",
        "\n",
        "\n",
        "    # interactionModel.add(Merge([XDmodel, XTmodel1], mode='concat', concat_axis=1))\n",
        "    interactionModel.add(layers.Concatenate([XDmodel, XTmodel1]))\n",
        "\n",
        "\n",
        "    # Fully connected\n",
        "    interactionModel.add(Dense(1024, activation='relu'))\n",
        "    interactionModel.add(Dropout(0.1))\n",
        "    interactionModel.add(Dense(1024, activation='relu'))\n",
        "    interactionModel.add(Dropout(0.1))\n",
        "    interactionModel.add(Dense(512, activation='relu'))\n",
        "\n",
        "    interactionModel.add(Dense(1, kernel_initializer='normal'))\n",
        "    interactionModel.compile(optimizer='adam', loss='mean_squared_error', metrics=[cindex_score])\n",
        "\n",
        "    print(interactionModel.summary())\n",
        "    plot_model(interactionModel, to_file='figures/build_single_protein.png')\n",
        "\n",
        "    return interactionModel"
      ],
      "metadata": {
        "id": "wFLhJvD5BEzY"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_baseline(FLAGS, NUM_FILTERS, FILTER_LENGTH1, FILTER_LENGTH2):\n",
        "    interactionModel = Sequential()\n",
        "\n",
        "    XDmodel = Sequential()\n",
        "    XDmodel.add(Dense(1, activation='linear', input_shape=(FLAGS.drug_count, )))\n",
        "\n",
        "    XTmodel = Sequential()\n",
        "    XTmodel.add(Dense(1, activation='linear', input_shape=(FLAGS.target_count,)))\n",
        "\n",
        "\n",
        "    # interactionModel.add(Merge([XDmodel, XTmodel], mode='concat', concat_axis=1))\n",
        "    interactionModel.add(layers.Concatenate([XDmodel, XTmodel]))\n",
        "\n",
        "    # Fully connected\n",
        "    interactionModel.add(Dense(1024, activation='relu'))\n",
        "    interactionModel.add(Dropout(0.1))\n",
        "    interactionModel.add(Dense(1024, activation='relu'))\n",
        "    interactionModel.add(Dropout(0.1))\n",
        "    interactionModel.add(Dense(512, activation='relu'))\n",
        "\n",
        "    interactionModel.add(Dense(1, kernel_initializer='normal'))\n",
        "    interactionModel.compile(optimizer='adam', loss='mean_squared_error', metrics=[cindex_score])\n",
        "\n",
        "    print(interactionModel.summary())\n",
        "    plot_model(interactionModel, to_file='figures/build_baseline.png', show_shapes=True, show_layer_names=False, rankdir='TB', expand_nested=False, style=0, color=True, dpi=96)\n",
        "\n",
        "    # plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=False, rankdir='TB', expand_nested=False, style=0, color=True, dpi=96)\n",
        "    # model = Sequential()\n",
        "    # model.add(Dense(2, input_dim=1, activation='relu'))\n",
        "    # model.add(Dense(1, activation='sigmoid'))\n",
        "    # plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
        "    return interactionModel"
      ],
      "metadata": {
        "id": "HmmjwKV1BGoN"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def nfold_1_2_3_setting_sample(XD, XT,  Y, label_row_inds, label_col_inds, measure, runmethod,  FLAGS, dataset):\n",
        "\n",
        "    bestparamlist = []\n",
        "    test_set, outer_train_sets = dataset.read_sets(FLAGS)\n",
        "\n",
        "    foldinds = len(outer_train_sets)\n",
        "\n",
        "    test_sets = []\n",
        "    ## TRAIN AND VAL\n",
        "    val_sets = []\n",
        "    train_sets = []\n",
        "\n",
        "    #logger.info('Start training')\n",
        "    for val_foldind in range(foldinds):\n",
        "        val_fold = outer_train_sets[val_foldind]\n",
        "        val_sets.append(val_fold)\n",
        "        otherfolds = deepcopy(outer_train_sets)\n",
        "        otherfolds.pop(val_foldind)\n",
        "        otherfoldsinds = [item for sublist in otherfolds for item in sublist]\n",
        "        train_sets.append(otherfoldsinds)\n",
        "        test_sets.append(test_set)\n",
        "        print(\"val set\", str(len(val_fold)))\n",
        "        print(\"train set\", str(len(otherfoldsinds)))\n",
        "\n",
        "\n",
        "\n",
        "    bestparamind, best_param_list, bestperf, all_predictions_not_need, losses_not_need = general_nfold_cv(XD, XT,  Y, label_row_inds, label_col_inds,\n",
        "                                                                                                measure, runmethod, FLAGS, train_sets, val_sets)\n",
        "\n",
        "    #print(\"Test Set len\", str(len(test_set)))\n",
        "    #print(\"Outer Train Set len\", str(len(outer_train_sets)))\n",
        "    bestparam, best_param_list, bestperf, all_predictions, all_losses = general_nfold_cv(XD, XT,  Y, label_row_inds, label_col_inds,\n",
        "                                                                                                measure, runmethod, FLAGS, train_sets, test_sets)\n",
        "\n",
        "    testperf = all_predictions[bestparamind]##pointer pos\n",
        "\n",
        "    logging(\"---FINAL RESULTS-----\", FLAGS)\n",
        "    logging(\"best param index = %s,  best param = %.5f\" %\n",
        "            (bestparamind, bestparam), FLAGS)\n",
        "\n",
        "\n",
        "    testperfs = []\n",
        "    testloss= []\n",
        "\n",
        "    avgperf = 0.\n",
        "\n",
        "    for test_foldind in range(len(test_sets)):\n",
        "        foldperf = all_predictions[bestparamind][test_foldind]\n",
        "        foldloss = all_losses[bestparamind][test_foldind]\n",
        "        testperfs.append(foldperf)\n",
        "        testloss.append(foldloss)\n",
        "        avgperf += foldperf\n",
        "\n",
        "    avgperf = avgperf / len(test_sets)\n",
        "    avgloss = np.mean(testloss)\n",
        "    teststd = np.std(testperfs)\n",
        "\n",
        "    logging(\"Test Performance CI\", FLAGS)\n",
        "    logging(testperfs, FLAGS)\n",
        "    logging(\"Test Performance MSE\", FLAGS)\n",
        "    logging(testloss, FLAGS)\n",
        "\n",
        "    return avgperf, avgloss, teststd"
      ],
      "metadata": {
        "id": "u0UG-0NcBL9Z"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def general_nfold_cv(XD, XT,  Y, label_row_inds, label_col_inds, prfmeasure, runmethod, FLAGS, labeled_sets, val_sets): ## BURAYA DA FLAGS LAZIM????\n",
        "\n",
        "    paramset1 = FLAGS.num_windows                              #[32]#[32,  512] #[32, 128]  # filter numbers\n",
        "    paramset2 = FLAGS.smi_window_lengths                               #[4, 8]#[4,  32] #[4,  8] #filter length smi\n",
        "    paramset3 = FLAGS.seq_window_lengths                               #[8, 12]#[64,  256] #[64, 192]#[8, 192, 384]\n",
        "    epoch = FLAGS.num_epoch                                 #100\n",
        "    batchsz = FLAGS.batch_size                             #256\n",
        "\n",
        "    logging(\"---Parameter Search-----\", FLAGS)\n",
        "\n",
        "    w = len(val_sets)\n",
        "    h = len(paramset1) * len(paramset2) * len(paramset3)\n",
        "\n",
        "    all_predictions = [[0 for x in range(w)] for y in range(h)]\n",
        "    all_losses = [[0 for x in range(w)] for y in range(h)]\n",
        "    print(all_predictions)\n",
        "\n",
        "    for foldind in range(len(val_sets)):\n",
        "        valinds = val_sets[foldind]\n",
        "        labeledinds = labeled_sets[foldind]\n",
        "\n",
        "        Y_train = np.mat(np.copy(Y))\n",
        "\n",
        "        params = {}\n",
        "        XD_train = XD\n",
        "        XT_train = XT\n",
        "        trrows = label_row_inds[labeledinds]\n",
        "        trcols = label_col_inds[labeledinds]\n",
        "\n",
        "        XD_train = XD[trrows]\n",
        "        XT_train = XT[trcols]\n",
        "\n",
        "        train_drugs, train_prots,  train_Y = prepare_interaction_pairs(XD, XT, Y, trrows, trcols)\n",
        "\n",
        "        terows = label_row_inds[valinds]\n",
        "        tecols = label_col_inds[valinds]\n",
        "        #print(\"terows\", str(terows), str(len(terows)))\n",
        "        #print(\"tecols\", str(tecols), str(len(tecols)))\n",
        "\n",
        "        val_drugs, val_prots,  val_Y = prepare_interaction_pairs(XD, XT,  Y, terows, tecols)\n",
        "\n",
        "\n",
        "        pointer = 0\n",
        "\n",
        "        for param1ind in range(len(paramset1)): #hidden neurons\n",
        "            param1value = paramset1[param1ind]\n",
        "            for param2ind in range(len(paramset2)): #learning rate\n",
        "                param2value = paramset2[param2ind]\n",
        "\n",
        "                for param3ind in range(len(paramset3)):\n",
        "                    param3value = paramset3[param3ind]\n",
        "\n",
        "                    gridmodel = runmethod(FLAGS, param1value, param2value, param3value)\n",
        "                    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=15)\n",
        "                    gridres = gridmodel.fit(([np.array(train_drugs),np.array(train_prots) ]), np.array(train_Y), batch_size=batchsz, epochs=epoch,\n",
        "                            validation_data=( ([np.array(val_drugs), np.array(val_prots) ]), np.array(val_Y)),  shuffle=False, callbacks=[es] )\n",
        "\n",
        "\n",
        "                    predicted_labels = gridmodel.predict([np.array(val_drugs), np.array(val_prots) ])\n",
        "                    loss, rperf2 = gridmodel.evaluate(([np.array(val_drugs),np.array(val_prots) ]), np.array(val_Y), verbose=0)\n",
        "                    rperf = prfmeasure(val_Y, predicted_labels)\n",
        "                    rperf = rperf[0]\n",
        "\n",
        "\n",
        "                    logging(\"P1 = %d,  P2 = %d, P3 = %d, Fold = %d, CI-i = %f, CI-ii = %f, MSE = %f\" %\n",
        "                    (param1ind, param2ind, param3ind, foldind, rperf, rperf2, loss), FLAGS)\n",
        "\n",
        "                    plotLoss(gridres, param1ind, param2ind, param3ind, foldind)\n",
        "\n",
        "                    all_predictions[pointer][foldind] =rperf #TODO FOR EACH VAL SET allpredictions[pointer][foldind]\n",
        "                    all_losses[pointer][foldind]= loss\n",
        "\n",
        "                    pointer +=1\n",
        "\n",
        "    bestperf = -float('Inf')\n",
        "    bestpointer = None\n",
        "\n",
        "\n",
        "    best_param_list = []\n",
        "    ##Take average according to folds, then chooose best params\n",
        "    pointer = 0\n",
        "    for param1ind in range(len(paramset1)):\n",
        "            for param2ind in range(len(paramset2)):\n",
        "                for param3ind in range(len(paramset3)):\n",
        "\n",
        "                    avgperf = 0.\n",
        "                    for foldind in range(len(val_sets)):\n",
        "                        foldperf = all_predictions[pointer][foldind]\n",
        "                        avgperf += foldperf\n",
        "                    avgperf /= len(val_sets)\n",
        "                    #print(epoch, batchsz, avgperf)\n",
        "                    if avgperf > bestperf:\n",
        "                        bestperf = avgperf\n",
        "                        bestpointer = pointer\n",
        "                        best_param_list = [param1ind, param2ind, param3ind]\n",
        "\n",
        "                    pointer +=1\n",
        "\n",
        "    return  bestpointer, best_param_list, bestperf, all_predictions, all_losses"
      ],
      "metadata": {
        "id": "ch3doSpDBR2L"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cindex_score(y_true, y_pred):\n",
        "\n",
        "    g = tf.subtract(tf.expand_dims(y_pred, -1), y_pred)\n",
        "    g = tf.cast(g == 0.0, tf.float32) * 0.5 + tf.cast(g > 0.0, tf.float32)\n",
        "\n",
        "    f = tf.subtract(tf.expand_dims(y_true, -1), y_true) > 0.0\n",
        "    f = tf.compat.v1.matrix_band_part(tf.cast(f, tf.float32), -1, 0)\n",
        "\n",
        "    g = tf.reduce_sum(tf.multiply(g, f))\n",
        "    f = tf.reduce_sum(f)\n",
        "\n",
        "    return tf.where(tf.equal(g, 0), 0.0, g/f) #select"
      ],
      "metadata": {
        "id": "rA6j_lcsBVGN"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plotLoss(history, batchind, epochind, param3ind, foldind):\n",
        "\n",
        "    figname = \"b\"+str(batchind) + \"_e\" + str(epochind) + \"_\" + str(param3ind) + \"_\"  + str( foldind) + \"_\" + str(time.time())\n",
        "    plt.figure()\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "\t  #plt.legend(['trainloss', 'valloss', 'cindex', 'valcindex'], loc='upper left')\n",
        "    plt.legend(['trainloss', 'valloss'], loc='upper left')\n",
        "    plt.savefig(\"figures/\"+figname +\".png\" , dpi=None, facecolor='w', edgecolor='w', orientation='portrait',\n",
        "                    papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "    ## PLOT CINDEX\n",
        "    plt.figure()\n",
        "    plt.title('model concordance index')\n",
        "    plt.ylabel('cindex')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.plot(history.history['cindex_score'])\n",
        "    plt.plot(history.history['val_cindex_score'])\n",
        "    plt.legend(['traincindex', 'valcindex'], loc='upper left')\n",
        "    plt.savefig(\"figures/\"+figname + \"_acc.png\" , dpi=None, facecolor='w', edgecolor='w', orientation='portrait',\n",
        "                            papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "ftE5B34fBXKP"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_interaction_pairs(XD, XT,  Y, rows, cols):\n",
        "    drugs = []\n",
        "    targets = []\n",
        "    targetscls = []\n",
        "    affinity=[]\n",
        "\n",
        "    for pair_ind in range(len(rows)):\n",
        "        drug = XD[rows[pair_ind]]\n",
        "        drugs.append(drug)\n",
        "\n",
        "        target=XT[cols[pair_ind]]\n",
        "        targets.append(target)\n",
        "\n",
        "        affinity.append(Y[rows[pair_ind],cols[pair_ind]])\n",
        "\n",
        "    drug_data = np.stack(drugs)\n",
        "    target_data = np.stack(targets)\n",
        "\n",
        "    return drug_data,target_data,  affinity"
      ],
      "metadata": {
        "id": "szCkZGgpBYyu"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#datahelper file:\n",
        "\n",
        "## ######################## ##\n",
        "#\n",
        "#  Define CHARSET, CHARLEN\n",
        "#\n",
        "## ######################## ##\n",
        "\n",
        "# CHARPROTSET = { 'A': 0, 'C': 1, 'D': 2, 'E': 3, 'F': 4, 'G': 5, 'H': 6, \\\n",
        "#             'I': 7, 'K': 8, 'L': 9, 'M': 10, 'N': 11, 'P': 12, 'Q': 13, \\\n",
        "#             'R': 14, 'S': 15, 'T': 16, 'V': 17, 'W': 18, 'Y': 19, 'X': 20, \\\n",
        "#             'O': 20, 'U': 20,\n",
        "#             'B': (2, 11),\n",
        "#             'Z': (3, 13),\n",
        "#             'J': (7, 9) }\n",
        "# CHARPROTLEN = 21\n",
        "\n",
        "CHARPROTSET = { \"A\": 1, \"C\": 2, \"B\": 3, \"E\": 4, \"D\": 5, \"G\": 6,\n",
        "\t\t\t\t\"F\": 7, \"I\": 8, \"H\": 9, \"K\": 10, \"M\": 11, \"L\": 12,\n",
        "\t\t\t\t\"O\": 13, \"N\": 14, \"Q\": 15, \"P\": 16, \"S\": 17, \"R\": 18,\n",
        "\t\t\t\t\"U\": 19, \"T\": 20, \"W\": 21,\n",
        "\t\t\t\t\"V\": 22, \"Y\": 23, \"X\": 24,\n",
        "\t\t\t\t\"Z\": 25 }\n",
        "\n",
        "CHARPROTLEN = 25\n",
        "\n",
        "CHARCANSMISET = { \"#\": 1, \"%\": 2, \")\": 3, \"(\": 4, \"+\": 5, \"-\": 6,\n",
        "\t\t\t \".\": 7, \"1\": 8, \"0\": 9, \"3\": 10, \"2\": 11, \"5\": 12,\n",
        "\t\t\t \"4\": 13, \"7\": 14, \"6\": 15, \"9\": 16, \"8\": 17, \"=\": 18,\n",
        "\t\t\t \"A\": 19, \"C\": 20, \"B\": 21, \"E\": 22, \"D\": 23, \"G\": 24,\n",
        "\t\t\t \"F\": 25, \"I\": 26, \"H\": 27, \"K\": 28, \"M\": 29, \"L\": 30,\n",
        "\t\t\t \"O\": 31, \"N\": 32, \"P\": 33, \"S\": 34, \"R\": 35, \"U\": 36,\n",
        "\t\t\t \"T\": 37, \"W\": 38, \"V\": 39, \"Y\": 40, \"[\": 41, \"Z\": 42,\n",
        "\t\t\t \"]\": 43, \"_\": 44, \"a\": 45, \"c\": 46, \"b\": 47, \"e\": 48,\n",
        "\t\t\t \"d\": 49, \"g\": 50, \"f\": 51, \"i\": 52, \"h\": 53, \"m\": 54,\n",
        "\t\t\t \"l\": 55, \"o\": 56, \"n\": 57, \"s\": 58, \"r\": 59, \"u\": 60,\n",
        "\t\t\t \"t\": 61, \"y\": 62}\n",
        "\n",
        "CHARCANSMILEN = 62\n",
        "\n",
        "CHARISOSMISET = {\"#\": 29, \"%\": 30, \")\": 31, \"(\": 1, \"+\": 32, \"-\": 33, \"/\": 34, \".\": 2,\n",
        "\t\t\t\t\"1\": 35, \"0\": 3, \"3\": 36, \"2\": 4, \"5\": 37, \"4\": 5, \"7\": 38, \"6\": 6,\n",
        "\t\t\t\t\"9\": 39, \"8\": 7, \"=\": 40, \"A\": 41, \"@\": 8, \"C\": 42, \"B\": 9, \"E\": 43,\n",
        "\t\t\t\t\"D\": 10, \"G\": 44, \"F\": 11, \"I\": 45, \"H\": 12, \"K\": 46, \"M\": 47, \"L\": 13,\n",
        "\t\t\t\t\"O\": 48, \"N\": 14, \"P\": 15, \"S\": 49, \"R\": 16, \"U\": 50, \"T\": 17, \"W\": 51,\n",
        "\t\t\t\t\"V\": 18, \"Y\": 52, \"[\": 53, \"Z\": 19, \"]\": 54, \"\\\\\": 20, \"a\": 55, \"c\": 56,\n",
        "\t\t\t\t\"b\": 21, \"e\": 57, \"d\": 22, \"g\": 58, \"f\": 23, \"i\": 59, \"h\": 24, \"m\": 60,\n",
        "\t\t\t\t\"l\": 25, \"o\": 61, \"n\": 26, \"s\": 62, \"r\": 27, \"u\": 63, \"t\": 28, \"y\": 64}\n",
        "\n",
        "CHARISOSMILEN = 64\n",
        "\n",
        "\n",
        "## ######################## ##\n",
        "#\n",
        "#  Encoding Helpers\n",
        "#\n",
        "## ######################## ##\n",
        "\n",
        "#  Y = -(np.log10(Y/(math.pow(math.e,9))))\n",
        "\n",
        "def one_hot_smiles(line, MAX_SMI_LEN, smi_ch_ind):\n",
        "\tX = np.zeros((MAX_SMI_LEN, len(smi_ch_ind))) #+1\n",
        "\n",
        "\tfor i, ch in enumerate(line[:MAX_SMI_LEN]):\n",
        "\t\tX[i, (smi_ch_ind[ch]-1)] = 1\n",
        "\n",
        "\treturn X #.tolist()\n",
        "\n",
        "def one_hot_sequence(line, MAX_SEQ_LEN, smi_ch_ind):\n",
        "\tX = np.zeros((MAX_SEQ_LEN, len(smi_ch_ind)))\n",
        "\tfor i, ch in enumerate(line[:MAX_SEQ_LEN]):\n",
        "\t\tX[i, (smi_ch_ind[ch])-1] = 1\n",
        "\n",
        "\treturn X #.tolist()\n",
        "\n",
        "\n",
        "def label_smiles(line, MAX_SMI_LEN, smi_ch_ind):\n",
        "\tX = np.zeros(MAX_SMI_LEN)\n",
        "\tfor i, ch in enumerate(line[:MAX_SMI_LEN]): #\tx, smi_ch_ind, y\n",
        "\t\tX[i] = smi_ch_ind[ch]\n",
        "\n",
        "\treturn X #.tolist()\n",
        "\n",
        "def label_sequence(line, MAX_SEQ_LEN, smi_ch_ind):\n",
        "\tX = np.zeros(MAX_SEQ_LEN)\n",
        "\n",
        "\tfor i, ch in enumerate(line[:MAX_SEQ_LEN]):\n",
        "\t\tX[i] = smi_ch_ind[ch]\n",
        "\n",
        "\treturn X #.tolist()\n",
        "\n",
        "\n",
        "\n",
        "## ######################## ##\n",
        "#\n",
        "#  DATASET Class\n",
        "#\n",
        "## ######################## ##\n",
        "# works for large dataset\n",
        "class DataSet(object):\n",
        "  def __init__(self, fpath, setting_no, seqlen, smilen, need_shuffle = False):\n",
        "    self.SEQLEN = seqlen\n",
        "    self.SMILEN = smilen\n",
        "    #self.NCLASSES = n_classes\n",
        "    self.charseqset = CHARPROTSET\n",
        "    self.charseqset_size = CHARPROTLEN\n",
        "\n",
        "    self.charsmiset = CHARISOSMISET ###HERE CAN BE EDITED\n",
        "    self.charsmiset_size = CHARISOSMILEN\n",
        "    self.PROBLEMSET = setting_no\n",
        "\n",
        "    # read raw file\n",
        "    # self._raw = self.read_sets( FLAGS)\n",
        "\n",
        "    # iteration flags\n",
        "    # self._num_data = len(self._raw)\n",
        "\n",
        "\n",
        "  def read_sets(self, FLAGS): ### fpath should be the dataset folder /kiba/ or /davis/\n",
        "    fpath = FLAGS.dataset_path\n",
        "    setting_no = FLAGS.problem_type\n",
        "    print(\"Reading %s start\" % fpath)\n",
        "\n",
        "    test_fold = json.load(open(fpath + \"folds/test_fold_setting\" + str(setting_no)+\".txt\"))\n",
        "    train_folds = json.load(open(fpath + \"folds/train_fold_setting\" + str(setting_no)+\".txt\"))\n",
        "\n",
        "    return test_fold, train_folds\n",
        "\n",
        "  def parse_data(self, FLAGS,  with_label=True):\n",
        "    fpath = FLAGS.dataset_path\n",
        "    print(\"Read %s start\" % fpath)\n",
        "\n",
        "    ligands = json.load(open(fpath+\"ligands_can.txt\"), object_pairs_hook=OrderedDict)\n",
        "    proteins = json.load(open(fpath+\"proteins.txt\"), object_pairs_hook=OrderedDict)\n",
        "\n",
        "    Y = pickle.load(open(fpath + \"Y\",\"rb\"), encoding='latin1') ### TODO: read from raw\n",
        "    if FLAGS.is_log:\n",
        "        Y = -(np.log10(Y/(math.pow(10,9))))\n",
        "\n",
        "    XD = []\n",
        "    XT = []\n",
        "\n",
        "    if with_label:\n",
        "        for d in ligands.keys():\n",
        "            XD.append(label_smiles(ligands[d], self.SMILEN, self.charsmiset))\n",
        "\n",
        "        for t in proteins.keys():\n",
        "            XT.append(label_sequence(proteins[t], self.SEQLEN, self.charseqset))\n",
        "    else:\n",
        "        for d in ligands.keys():\n",
        "            XD.append(one_hot_smiles(ligands[d], self.SMILEN, self.charsmiset))\n",
        "\n",
        "        for t in proteins.keys():\n",
        "            XT.append(one_hot_sequence(proteins[t], self.SEQLEN, self.charseqset))\n",
        "\n",
        "    return XD, XT, Y"
      ],
      "metadata": {
        "id": "GbujiAd7BzhO"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def experiment(FLAGS, perfmeasure, deepmethod, foldcount=6): #5-fold cross validation + test\n",
        "\n",
        "    #Input\n",
        "    #XD: [drugs, features] sized array (features may also be similarities with other drugs\n",
        "    #XT: [targets, features] sized array (features may also be similarities with other targets\n",
        "    #Y: interaction values, can be real values or binary (+1, -1), insert value float(\"nan\") for unknown entries\n",
        "    #perfmeasure: function that takes as input a list of correct and predicted outputs, and returns performance\n",
        "    #higher values should be better, so if using error measures use instead e.g. the inverse -error(Y, P)\n",
        "    #foldcount: number of cross-validation folds for settings 1-3, setting 4 always runs 3x3 cross-validation\n",
        "\n",
        "\n",
        "    dataset = DataSet( fpath = FLAGS.dataset_path, ### BUNU ARGS DA GUNCELLE\n",
        "                      setting_no = FLAGS.problem_type, ##BUNU ARGS A EKLE\n",
        "                      seqlen = FLAGS.max_seq_len,\n",
        "                      smilen = FLAGS.max_smi_len,\n",
        "                      need_shuffle = False )\n",
        "    # set character set size\n",
        "    FLAGS.charseqset_size = dataset.charseqset_size\n",
        "    FLAGS.charsmiset_size = dataset.charsmiset_size\n",
        "\n",
        "    XD, XT, Y = dataset.parse_data(FLAGS)\n",
        "\n",
        "    XD = np.asarray(XD)\n",
        "    XT = np.asarray(XT)\n",
        "    Y = np.asarray(Y)\n",
        "\n",
        "    drugcount = XD.shape[0]\n",
        "    print(drugcount)\n",
        "    targetcount = XT.shape[0]\n",
        "    print(targetcount)\n",
        "\n",
        "    FLAGS.drug_count = drugcount\n",
        "    FLAGS.target_count = targetcount\n",
        "\n",
        "    label_row_inds, label_col_inds = np.where(np.isnan(Y)==False)  #basically finds the point address of affinity [x,y]\n",
        "\n",
        "    if not os.path.exists(figdir):\n",
        "        os.makedirs(figdir)\n",
        "\n",
        "    print(FLAGS.log_dir)\n",
        "    S1_avgperf, S1_avgloss, S1_teststd = nfold_1_2_3_setting_sample(XD, XT, Y, label_row_inds, label_col_inds,\n",
        "                                                                     perfmeasure, deepmethod, FLAGS, dataset)\n",
        "\n",
        "    logging(\"Setting \" + str(FLAGS.problem_type), FLAGS)\n",
        "    logging(\"avg_perf = %.5f,  avg_mse = %.5f, std = %.5f\" %\n",
        "            (S1_avgperf, S1_avgloss, S1_teststd), FLAGS)"
      ],
      "metadata": {
        "id": "xSF4d4-TBdFs"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_regression( FLAGS ):\n",
        "\n",
        "    perfmeasure = get_cindex\n",
        "    deepmethod = build_combined_categorical\n",
        "\n",
        "    experiment(FLAGS, perfmeasure, deepmethod)"
      ],
      "metadata": {
        "id": "XAH8cX0WBfrP"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__==\"__main__\":\n",
        "\n",
        "    FLAGS = argparser()\n",
        "    FLAGS.num_windows = [32]\n",
        "    FLAGS.seq_window_lengths = [8,12]\n",
        "    FLAGS.smi_window_lengths = [4,8]\n",
        "    FLAGS.batch_size = 256\n",
        "    FLAGS.num_epoch = 50\n",
        "    FLAGS.max_seq_len = 1000\n",
        "    FLAGS.max_smi_len = 100\n",
        "    FLAGS.dataset_path = 'data/kiba/'\n",
        "    FLAGS.problem_type = 1\n",
        "    FLAGS.log_dir = 'logs/'+str(time.time()) + \"/\"\n",
        "\n",
        "    if not os.path.exists(FLAGS.log_dir):\n",
        "      os.makedirs(FLAGS.log_dir)\n",
        "\n",
        "    logging(str(FLAGS), FLAGS)\n",
        "    run_regression(FLAGS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "I0_dBBYuBhNZ",
        "outputId": "db0adbb5-b885-4ebd-8534-2c0755e94bb1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Read data/kiba/ start\n",
            "2111\n",
            "229\n",
            "logs/1691844457.1057656/\n",
            "Reading data/kiba/ start\n",
            "val set 19709\n",
            "train set 78836\n",
            "val set 19709\n",
            "train set 78836\n",
            "val set 19709\n",
            "train set 78836\n",
            "val set 19709\n",
            "train set 78836\n",
            "val set 19709\n",
            "train set 78836\n",
            "[[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]]\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 100)]        0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 1000)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 100, 128)     8320        ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, 1000, 128)    3328        ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)                (None, 97, 32)       16416       ['embedding[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_3 (Conv1D)              (None, 993, 32)      32800       ['embedding_1[0][0]']            \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)              (None, 94, 64)       8256        ['conv1d[0][0]']                 \n",
            "                                                                                                  \n",
            " conv1d_4 (Conv1D)              (None, 986, 64)      16448       ['conv1d_3[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_2 (Conv1D)              (None, 91, 96)       24672       ['conv1d_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_5 (Conv1D)              (None, 979, 96)      49248       ['conv1d_4[0][0]']               \n",
            "                                                                                                  \n",
            " global_max_pooling1d (GlobalMa  (None, 96)          0           ['conv1d_2[0][0]']               \n",
            " xPooling1D)                                                                                      \n",
            "                                                                                                  \n",
            " global_max_pooling1d_1 (Global  (None, 96)          0           ['conv1d_5[0][0]']               \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 192)          0           ['global_max_pooling1d[0][0]',   \n",
            "                                                                  'global_max_pooling1d_1[0][0]'] \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 1024)         197632      ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 1024)         0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 1024)         1049600     ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 1024)         0           ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 512)          524800      ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 1)            513         ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,932,033\n",
            "Trainable params: 1,932,033\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n",
            "308/308 [==============================] - 45s 89ms/step - loss: 3.0700 - cindex_score: 0.5990 - val_loss: 0.5188 - val_cindex_score: 0.7094\n",
            "Epoch 2/50\n",
            "308/308 [==============================] - 23s 76ms/step - loss: 0.5981 - cindex_score: 0.6727 - val_loss: 0.4726 - val_cindex_score: 0.7309\n",
            "Epoch 3/50\n",
            "308/308 [==============================] - 25s 80ms/step - loss: 0.5648 - cindex_score: 0.6982 - val_loss: 0.4662 - val_cindex_score: 0.7417\n",
            "Epoch 4/50\n",
            "308/308 [==============================] - 24s 79ms/step - loss: 0.5508 - cindex_score: 0.7103 - val_loss: 0.4656 - val_cindex_score: 0.7452\n",
            "Epoch 5/50\n",
            "308/308 [==============================] - 25s 81ms/step - loss: 0.5176 - cindex_score: 0.7188 - val_loss: 0.4407 - val_cindex_score: 0.7499\n",
            "Epoch 6/50\n",
            "308/308 [==============================] - 25s 80ms/step - loss: 0.4966 - cindex_score: 0.7236 - val_loss: 0.4657 - val_cindex_score: 0.7519\n",
            "Epoch 7/50\n",
            "308/308 [==============================] - 25s 82ms/step - loss: 0.5031 - cindex_score: 0.7266 - val_loss: 0.4077 - val_cindex_score: 0.7528\n",
            "Epoch 8/50\n",
            "308/308 [==============================] - 25s 80ms/step - loss: 0.4866 - cindex_score: 0.7291 - val_loss: 0.4086 - val_cindex_score: 0.7512\n",
            "Epoch 9/50\n",
            "308/308 [==============================] - 25s 80ms/step - loss: 0.4870 - cindex_score: 0.7307 - val_loss: 0.4100 - val_cindex_score: 0.7509\n",
            "Epoch 10/50\n",
            "308/308 [==============================] - 25s 83ms/step - loss: 0.4823 - cindex_score: 0.7340 - val_loss: 0.4321 - val_cindex_score: 0.7554\n",
            "Epoch 11/50\n",
            "308/308 [==============================] - 25s 80ms/step - loss: 0.4747 - cindex_score: 0.7359 - val_loss: 0.4498 - val_cindex_score: 0.7541\n",
            "Epoch 12/50\n",
            "308/308 [==============================] - 25s 83ms/step - loss: 0.4639 - cindex_score: 0.7378 - val_loss: 0.4045 - val_cindex_score: 0.7573\n",
            "Epoch 13/50\n",
            "308/308 [==============================] - 25s 80ms/step - loss: 0.4534 - cindex_score: 0.7404 - val_loss: 0.4253 - val_cindex_score: 0.7628\n",
            "Epoch 14/50\n",
            "308/308 [==============================] - 26s 83ms/step - loss: 0.4333 - cindex_score: 0.7437 - val_loss: 0.3843 - val_cindex_score: 0.7642\n",
            "Epoch 15/50\n",
            "308/308 [==============================] - 25s 82ms/step - loss: 0.4146 - cindex_score: 0.7475 - val_loss: 0.3600 - val_cindex_score: 0.7690\n",
            "Epoch 16/50\n",
            "308/308 [==============================] - 24s 80ms/step - loss: 0.3965 - cindex_score: 0.7524 - val_loss: 0.3591 - val_cindex_score: 0.7749\n",
            "Epoch 17/50\n",
            "308/308 [==============================] - 25s 83ms/step - loss: 0.3901 - cindex_score: 0.7562 - val_loss: 0.3487 - val_cindex_score: 0.7759\n",
            "Epoch 18/50\n",
            "308/308 [==============================] - 25s 80ms/step - loss: 0.3723 - cindex_score: 0.7625 - val_loss: 0.3378 - val_cindex_score: 0.7816\n",
            "Epoch 19/50\n",
            "308/308 [==============================] - 25s 82ms/step - loss: 0.3603 - cindex_score: 0.7659 - val_loss: 0.3236 - val_cindex_score: 0.7852\n",
            "Epoch 20/50\n",
            "308/308 [==============================] - 24s 79ms/step - loss: 0.3526 - cindex_score: 0.7690 - val_loss: 0.3263 - val_cindex_score: 0.7810\n",
            "Epoch 21/50\n",
            "308/308 [==============================] - 25s 82ms/step - loss: 0.3465 - cindex_score: 0.7707 - val_loss: 0.3289 - val_cindex_score: 0.7913\n",
            "Epoch 22/50\n",
            "308/308 [==============================] - 24s 79ms/step - loss: 0.3459 - cindex_score: 0.7740 - val_loss: 0.3155 - val_cindex_score: 0.7937\n",
            "Epoch 23/50\n",
            "308/308 [==============================] - 24s 80ms/step - loss: 0.3308 - cindex_score: 0.7775 - val_loss: 0.3494 - val_cindex_score: 0.7937\n",
            "Epoch 24/50\n",
            "308/308 [==============================] - 24s 80ms/step - loss: 0.3247 - cindex_score: 0.7790 - val_loss: 0.3125 - val_cindex_score: 0.7969\n",
            "Epoch 25/50\n",
            "308/308 [==============================] - 24s 80ms/step - loss: 0.3171 - cindex_score: 0.7814 - val_loss: 0.3045 - val_cindex_score: 0.7978\n",
            "Epoch 26/50\n",
            "308/308 [==============================] - 24s 79ms/step - loss: 0.3098 - cindex_score: 0.7845 - val_loss: 0.2958 - val_cindex_score: 0.7977\n",
            "Epoch 27/50\n",
            "308/308 [==============================] - 25s 82ms/step - loss: 0.2988 - cindex_score: 0.7888 - val_loss: 0.3077 - val_cindex_score: 0.8005\n",
            "Epoch 28/50\n",
            "308/308 [==============================] - 24s 79ms/step - loss: 0.2916 - cindex_score: 0.7918 - val_loss: 0.2814 - val_cindex_score: 0.8064\n",
            "Epoch 29/50\n",
            "308/308 [==============================] - 25s 82ms/step - loss: 0.2810 - cindex_score: 0.7957 - val_loss: 0.2839 - val_cindex_score: 0.8052\n",
            "Epoch 30/50\n",
            "308/308 [==============================] - 24s 79ms/step - loss: 0.2715 - cindex_score: 0.7996 - val_loss: 0.2704 - val_cindex_score: 0.8120\n",
            "Epoch 31/50\n",
            "308/308 [==============================] - 25s 82ms/step - loss: 0.2606 - cindex_score: 0.8033 - val_loss: 0.2725 - val_cindex_score: 0.8124\n",
            "Epoch 32/50\n",
            "308/308 [==============================] - 24s 79ms/step - loss: 0.2544 - cindex_score: 0.8070 - val_loss: 0.2685 - val_cindex_score: 0.8157\n",
            "Epoch 33/50\n",
            "308/308 [==============================] - 24s 79ms/step - loss: 0.2447 - cindex_score: 0.8099 - val_loss: 0.2663 - val_cindex_score: 0.8153\n",
            "Epoch 34/50\n",
            "308/308 [==============================] - 24s 79ms/step - loss: 0.2386 - cindex_score: 0.8118 - val_loss: 0.2631 - val_cindex_score: 0.8195\n",
            "Epoch 35/50\n",
            "308/308 [==============================] - 24s 79ms/step - loss: 0.2322 - cindex_score: 0.8159 - val_loss: 0.2561 - val_cindex_score: 0.8160\n",
            "Epoch 36/50\n",
            "308/308 [==============================] - 25s 82ms/step - loss: 0.2278 - cindex_score: 0.8186 - val_loss: 0.2528 - val_cindex_score: 0.8204\n",
            "Epoch 37/50\n",
            "308/308 [==============================] - 25s 82ms/step - loss: 0.2173 - cindex_score: 0.8217 - val_loss: 0.2478 - val_cindex_score: 0.8226\n",
            "Epoch 38/50\n",
            "308/308 [==============================] - 25s 82ms/step - loss: 0.2058 - cindex_score: 0.8251 - val_loss: 0.2435 - val_cindex_score: 0.8241\n",
            "Epoch 39/50\n",
            "308/308 [==============================] - 24s 79ms/step - loss: 0.2052 - cindex_score: 0.8266 - val_loss: 0.2539 - val_cindex_score: 0.8175\n",
            "Epoch 40/50\n",
            "308/308 [==============================] - 24s 79ms/step - loss: 0.1943 - cindex_score: 0.8296 - val_loss: 0.2508 - val_cindex_score: 0.8230\n",
            "Epoch 41/50\n",
            "308/308 [==============================] - 25s 82ms/step - loss: 0.1877 - cindex_score: 0.8329 - val_loss: 0.2424 - val_cindex_score: 0.8240\n",
            "Epoch 42/50\n",
            "308/308 [==============================] - 24s 79ms/step - loss: 0.1806 - cindex_score: 0.8370 - val_loss: 0.2414 - val_cindex_score: 0.8240\n",
            "Epoch 43/50\n",
            "308/308 [==============================] - 25s 81ms/step - loss: 0.1768 - cindex_score: 0.8390 - val_loss: 0.2340 - val_cindex_score: 0.8273\n",
            "Epoch 44/50\n",
            "308/308 [==============================] - 25s 82ms/step - loss: 0.1708 - cindex_score: 0.8415 - val_loss: 0.2420 - val_cindex_score: 0.8247\n",
            "Epoch 45/50\n",
            "308/308 [==============================] - 24s 79ms/step - loss: 0.1722 - cindex_score: 0.8439 - val_loss: 0.2685 - val_cindex_score: 0.8277\n",
            "Epoch 46/50\n",
            "308/308 [==============================] - 24s 79ms/step - loss: 0.1726 - cindex_score: 0.8453 - val_loss: 0.2452 - val_cindex_score: 0.8286\n",
            "Epoch 47/50\n",
            "308/308 [==============================] - 25s 81ms/step - loss: 0.1594 - cindex_score: 0.8509 - val_loss: 0.2594 - val_cindex_score: 0.8319\n",
            "Epoch 48/50\n",
            "308/308 [==============================] - 24s 79ms/step - loss: 0.1528 - cindex_score: 0.8534 - val_loss: 0.2557 - val_cindex_score: 0.8302\n",
            "Epoch 49/50\n",
            "308/308 [==============================] - 24s 79ms/step - loss: 0.1517 - cindex_score: 0.8548 - val_loss: 0.2260 - val_cindex_score: 0.8340\n",
            "Epoch 50/50\n",
            "308/308 [==============================] - 24s 79ms/step - loss: 0.1632 - cindex_score: 0.8553 - val_loss: 0.2323 - val_cindex_score: 0.8316\n",
            "616/616 [==============================] - 3s 5ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-23b8d6430ea9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mrun_regression\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mFLAGS\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-23-d06c3f68124b>\u001b[0m in \u001b[0;36mrun_regression\u001b[0;34m(FLAGS)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdeepmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_combined_categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mexperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperfmeasure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeepmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-22-10c3c9a9ef63>\u001b[0m in \u001b[0;36mexperiment\u001b[0;34m(FLAGS, perfmeasure, deepmethod, foldcount)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     S1_avgperf, S1_avgloss, S1_teststd = nfold_1_2_3_setting_sample(XD, XT, Y, label_row_inds, label_col_inds,\n\u001b[0m\u001b[1;32m     42\u001b[0m                                                                      perfmeasure, deepmethod, FLAGS, dataset)\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-94f1cce37684>\u001b[0m in \u001b[0;36mnfold_1_2_3_setting_sample\u001b[0;34m(XD, XT, Y, label_row_inds, label_col_inds, measure, runmethod, FLAGS, dataset)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     bestparamind, best_param_list, bestperf, all_predictions_not_need, losses_not_need = general_nfold_cv(XD, XT,  Y, label_row_inds, label_col_inds,\n\u001b[0m\u001b[1;32m     28\u001b[0m                                                                                                 measure, runmethod, FLAGS, train_sets, val_sets)\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-92f7bfec8e4e>\u001b[0m in \u001b[0;36mgeneral_nfold_cv\u001b[0;34m(XD, XT, Y, label_row_inds, label_col_inds, prfmeasure, runmethod, FLAGS, labeled_sets, val_sets)\u001b[0m\n\u001b[1;32m     66\u001b[0m                     (param1ind, param2ind, param3ind, foldind, rperf, rperf2, loss), FLAGS)\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m                     \u001b[0mplotLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgridres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam1ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam2ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam3ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfoldind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                     \u001b[0mall_predictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpointer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfoldind\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mrperf\u001b[0m \u001b[0;31m#TODO FOR EACH VAL SET allpredictions[pointer][foldind]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-bc58200193b8>\u001b[0m in \u001b[0;36mplotLoss\u001b[0;34m(history, batchind, epochind, param3ind, foldind)\u001b[0m\n\u001b[1;32m     10\u001b[0m           \u001b[0;31m#plt.legend(['trainloss', 'valloss', 'cindex', 'valcindex'], loc='upper left')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'trainloss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'valloss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'upper left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     plt.savefig(\"figures/\"+figname +\".png\" , dpi=None, facecolor='w', edgecolor='w', orientation='portrait',\n\u001b[0m\u001b[1;32m     13\u001b[0m                     papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None)\n\u001b[1;32m     14\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1021\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1023\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1024\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Need this if 'transparent=True', to reset colors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[1;32m   3341\u001b[0m                         ax.patch._cm_set(facecolor='none', edgecolor='none'))\n\u001b[1;32m   3342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3343\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3345\u001b[0m     def ginput(self, n=1, timeout=30, show_clicks=True,\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2364\u001b[0m                 \u001b[0;31m# force the figure dpi to 72), so we need to set it again here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2366\u001b[0;31m                     result = print_method(\n\u001b[0m\u001b[1;32m   2367\u001b[0m                         \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2368\u001b[0m                         \u001b[0mfacecolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfacecolor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   2230\u001b[0m                 \"bbox_inches_restore\"}\n\u001b[1;32m   2231\u001b[0m             \u001b[0mskip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptional_kws\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2232\u001b[0;31m             print_method = functools.wraps(meth)(lambda *args, **kwargs: meth(\n\u001b[0m\u001b[1;32m   2233\u001b[0m                 *args, **{k: v for k, v in kwargs.items() if k not in skip}))\n\u001b[1;32m   2234\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Let third-parties do as they see fit.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: FigureCanvasAgg.print_png() got an unexpected keyword argument 'papertype'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DtdJvE7WCWkg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}